## Machine Learning 종류
머신러닝 알고리즘 선택 방법 ? 적절한 알고리즘을 선택하려면, 각 알고리즘의 특성을 파악해야 한다.

1. 분류 : 정답이 비연속적인 클래스(카테고리)이며, 정답과 입력 데이터의 조합을 학습하여 새로운 데이터의 클래스를 예측
2. 회귀 : 정답이 수치다. 정답과 입력 데이터의 조합을 학습해서 새로운 데이터에서 연속하는 값을 예측
3. 군집화 : 어떤 기준에 따라 데이터를 그룹으로 묶는다.
4. 차원 축소 : 시각화 또는 계산량 절감을 목적으로 고차원 데이터를 저차원 공간에 매핑
5. 그 외
    1. 추천: 사용자가 선호할만한 것을 추천
    2. 이상 탐지: 수상한 접근 등 평소와 다른 행동 검출
    3. 고빈도 패턴 마이닝: 데이터 안에서 발생 빈도가 높은 패턴 추출
    4. 강화 학습: 바둑, 장기처럼 정답이 불명확한 환경에서 앞으로 취할 행동을 선택하는 방법 학습

### 지도 학습(supervised learning)
훈련 데이터로부터 하나의 함수를 유추해내기 위한 기계 학습의 한 방법이다.

### 분류
기존에 존재하는 데이터의 카테고리 관계를 파악하고, 새롭게 관측된 데이터의 카테고리를 스스로 판별하는 과정

#### 단일 분류 vs 다중 분류

- 단일 분류 : 하나의 기준, 2개의 Group(ex. 하나의 메일이 왔을 때, 이 메일이 스팸인가?(Yes or No)에 대한 하나의 기준이 있고, 그에 따른 분류를 한다면 이는 단일 분류)
- 다중 분류 : 여러 개의 기준, 여러 개의 Group (ex. 수능 점수가 있고 그 점수가 몇 등급에 속하는지를 분류한다면, 이는 분류에 대한 기준이 총 9개이기 때문에 다중 분류)
  - 다중분류는 비지도학습인 Clustering 과 비슷하지만 클러스터링과 분류의 차이점은 이미 카테고리가 정해지의 여부
  - 만일 카테고리가 정해져있고 그 범주로 나누기만 한다면 분류, 카테고리 또한 생성의 대상이 된다면 클러스터링

즉, A 라는 input 이 들어왔을 때, 이것이 어떤 카테고리에 들어가는지 결정하는 알고리즘을 ‘분류’ 라고 한다.

#### Binary Class Classification Problem vs Multi-class Classification Problem
- Multi-class Classification Problem 은 Binary Class Classification Problem 의 extension(확장)일 뿐

#### 분류의 대표적인 알고리즘
- Perceptron
- Support Vector Machine(SVM)
- Logistic Regression

Training Dataset에서 먼저 Classification Boundary 를 찾아야 한다.

input 값이 [x, y] 일 때 output 이 0 이면 Group A, 1 이면 Group B이다. 
그리고 x, y축을 가지는 2차원 평면 좌표계에서 그 두개의 군집을 나누는 명확한 classification boundary 가 있고 그것이 직선형이다. 
그러면 linear binary classification 문제라고 한다.

그러면 이 linear 선의 값을 어떻게 찾을 것인가?

이 직선은 x2 = a*x1 + b 로 표현될 수 있다. 그리고 w0 + w1*x1 + w2*x2 = 0 으로도 표현될 수 있다. 
그러면 Training Dataset 을 통해서 w0, w1, w2 를 찾을 수가 있게 된다.

#### Perceptron 알고리즘
입력 벡터와 학습한 가중치 벡터를 곱한 값을 합한 값이 0 이상일 때는 클래스 1로, 0 미만일 때는 클래스 2로 분류하는 간단한 알고리즘이다.
퍼셉트론을 여러 층 쌓으면 신경망이 된다고 한다. 
여기서 퍼셉트론은 선형 분리 가능한 문제만 풀 수 있다고 하는데, 여기서 말하는 선형 분리 가능이란 위에서 이야기한 것처럼 데이터를 직선으로 두 클래스를 분리할 수 있는 경우를 말한다.

input이 있고, 각 input 과 곱해지는 weight(가중치) 가 있을 때, 그 연산의 값이 어떤 threshold(기준) 보다 크면 class 0, 작으면 class 1 이라고 하자. 
그러면 input 은 주어진 거니까, 우리는 weight, threshold 를 찾아야 하는데 각 input 에 대한 결과 값(label)을 아니까, weight, threshold 를 찾을 수 있게 된다. 
여기서 weight, threshold 의 값은 결국 앞에서 보았던, classification boundary 를 찾는 것이다.

이 값은 1 or -1 이 되고 이렇게 값이 두 군집으로 나뉘면서, 분류가 이루어진다. 위는 하나의 모델식이다. 
각 항의 x 값은 input 데이터의 값이고 w 의 값은 가중치이다. 그리고 총 항의 개수가 d(데이터의 개수)가 아닌 d+1인 이유는 모델을 artificial coordinate(임의의 좌표) x0을 1로 주었기 때문이다.